{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "runModel.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8qcqD-qVNVB"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from buildGenerator import buildGenerator\n",
        "from buildDiscriminator import buildDiscriminator\n",
        "\n",
        "# Change PATH variable to absolute/ relative path to the images directory on your machine which contains the train and val folders\n",
        "PATH = '../path/to/data' \n",
        "\n",
        "# Change these variables as per your need\n",
        "EPOCHS = 100\n",
        "BUFFER_SIZE = 14224\n",
        "BATCH_SIZE = 4\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "\n",
        "def load(image_file):\n",
        "    image = tf.io.read_file(image_file)\n",
        "    image = tf.image.decode_png(image)\n",
        "\n",
        "    w = tf.shape(image)[1]\n",
        "\n",
        "    w = w // 2\n",
        "    real_image = image[:, :w, :]\n",
        "    input_image = image[:, w:, :]\n",
        "\n",
        "    input_image = tf.cast(input_image, tf.float32)\n",
        "    real_image = tf.cast(real_image, tf.float32)\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "def resize(input_image, real_image, height, width):\n",
        "    input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    real_image = tf.image.resize(real_image, [height, width],\n",
        "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "def random_crop(input_image, real_image):\n",
        "    stacked_image = tf.stack([input_image, real_image], axis=0)\n",
        "    cropped_image = tf.image.random_crop(\n",
        "      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "\n",
        "    return cropped_image[0], cropped_image[1]\n",
        "\n",
        "def normalize(input_image, real_image):\n",
        "    input_image = (input_image / 127.5) - 1\n",
        "    real_image = (real_image / 127.5) - 1\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "@tf.function()\n",
        "def random_jitter(input_image, real_image):\n",
        "    input_image, real_image = resize(input_image, real_image, 286, 286)\n",
        "    input_image, real_image = random_crop(input_image, real_image)\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        real_image = tf.image.flip_left_right(real_image)\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "def load_image_train(image_file):\n",
        "    input_image, real_image = load(image_file)\n",
        "    input_image, real_image = random_jitter(input_image, real_image)\n",
        "    input_image, real_image = normalize(input_image, real_image)\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "def load_image_test(image_file):\n",
        "    input_image, real_image = load(image_file)\n",
        "    input_image, real_image = resize(input_image, real_image,\n",
        "                                   IMG_HEIGHT, IMG_WIDTH)\n",
        "    input_image, real_image = normalize(input_image, real_image)\n",
        "\n",
        "    return input_image, real_image\n",
        "\n",
        "train_dataset = tf.data.Dataset.list_files(PATH+'\\\\train\\\\*.png')\n",
        "train_dataset = train_dataset.map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.list_files(PATH+'\\\\val\\\\*.png')\n",
        "test_dataset = test_dataset.map(load_image_test)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "generator = buildGenerator()\n",
        "\n",
        "LAMBDA = 100\n",
        "\n",
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "\n",
        "    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "\n",
        "    return total_gen_loss, gan_loss, l1_loss\n",
        "\n",
        "discriminator = buildDiscriminator()\n",
        "\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "    total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "    return total_disc_loss\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "checkpoint_dir = './Sketch2Color_training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "def generate_images(model, test_input, tar):\n",
        "    prediction = model(test_input, training=True)\n",
        "    plt.figure(figsize=(15,15))\n",
        "\n",
        "    display_list = [test_input[0], tar[0], prediction[0]]\n",
        "    title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "import datetime\n",
        "log_dir=\"Sketch2Coloe_logs/\"\n",
        "\n",
        "summary_writer = tf.summary.create_file_writer(\n",
        "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "@tf.function\n",
        "def train_step(input_image, target, epoch):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        gen_output = generator(input_image, training=True)\n",
        "\n",
        "        disc_real_output = discriminator([input_image, target], training=True)\n",
        "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
        "\n",
        "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
        "                                          generator.trainable_variables)\n",
        "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                               discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                          generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                              discriminator.trainable_variables))\n",
        "\n",
        "    with summary_writer.as_default():\n",
        "        tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
        "        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
        "        tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
        "        tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n",
        "\n",
        "def fit(train_ds, epochs, test_ds):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for example_input, example_target in test_ds.take(1):\n",
        "            generate_images(generator, example_input, example_target)\n",
        "        print(\"Epoch: \", epoch)\n",
        "\n",
        "        for n, (input_image, target) in train_ds.enumerate():\n",
        "            print('.', end='')\n",
        "            if (n+1) % 100 == 0:\n",
        "                print()\n",
        "            train_step(input_image, target, epoch)\n",
        "        print()\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "        print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
        "                                                        time.time()-start))\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "fit(train_dataset, EPOCHS, test_dataset)\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "for example_input, example_target in test_dataset.take(5):\n",
        "    generate_images(generator, example_input, example_target)\n",
        "\n",
        "generator.save('AnimeColorizationModelv1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}